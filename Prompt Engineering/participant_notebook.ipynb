{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BEFORE WE START \n","*(Based on the Tutorial's README.MD)*\n","\n","- [x] Miniforge should be installed\n","        \n","        $ conda init powershell  # only for Windows users - requires terminal restart\n","        \n","        $ conda activate \n","        \n","        $ mamba create -n waw_ml python=3.10  # mamba/conda depending on what you use\n","        \n","        $ conda activate waw_ml\n","        \n","        $ pip install -r requirements.txt`\n","\n","NOTE: you might need to restart you VS code \n","- [x] Choose the kernel `waw_ml`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Run this piece of code to see the output text wrapped\n"," \n","from IPython.display import display, HTML, Markdown\n","# Set CSS for text wrapping in Jupyter notebook\n","display(HTML('''\n","<style>\n","    div.output_area pre {\n","        white-space: pre-wrap;\n","        word-wrap: break-word;\n","    }\n","</style>\n","'''))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Please  run this cell ONCE and restart your Kernel.\n","%pip install -qU langchain_mistralai ipywidgets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from helper.custom_lllm import CustomLLM\n","\n","from langchain_mistralai import ChatMistralAI\n","from langchain_core.output_parsers import StrOutputParser\n","\n","from dotenv import load_dotenv\n","import os\n","\n","# Load environment variables from the .env file\n","load_dotenv()\n","\n","# Access the API key using os.getenv\n","api_key = os.getenv(\"MISTRAL_API_KEY\")\n","api_key # You can have your own key on Mistral: https://console.mistral.ai/api-keys/"]},{"cell_type":"markdown","metadata":{},"source":["# Loading the Model \n","## (Locally or via API)\n","\n","Make sure to run Mistral7B locally with LMSTUDIO\n","\n","- On the left column menu, select `Developer` (The green icon)\n","- Select the model under **loaded models**: `llm mistral-7b-instruct-v0.2.Q5_K_M.gguf`\n","- On the left side, click the button `Start Server` (Do not change anything in the settings below it)\n","\n","You can see in the Server Logs that the *model* is accessible via  http://localhost:1234/v1/"]},{"cell_type":"markdown","metadata":{},"source":["### Loading models"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["\n","model_local = CustomLLM() # Load Mistral7b from LM Studio local server \n","\n","model_api = ChatMistralAI(model=\"open-mistral-7b\") # Load Mistral7b or Mixtral8x7B throught the API\n","# Note - The latest `open-mistral-nemo`: https://mistral.ai/news/mistral-nemo/\n","# All models: https://docs.mistral.ai/getting-started/models/\n","\n","# CHOOSE THE MODEL YOU WANT TO USE"]},{"cell_type":"markdown","metadata":{},"source":["### Test Run"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a prompt\n","prompt = '''\n","    What is DLR?\n","    '''\n","\n","# Chain: contains the mode and the output\n","chain =   model_local | StrOutputParser()\n","\n","response = chain.invoke(prompt)\n","print(\"RESPONSE from Local Mistral (With Quantization)\")\n","print(\"-\"*len(\"RESPONSE from Local Mistral (With Quantization)\"))\n","print(response)\n"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"images/doit.png\" alt=\"drawing\" width=\"24px\"/>  `TRYITYourself_1`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#  <TRYITYourself_1>: RERUN with Mistral API\n","chain_api =  None # <REDEFINE CHAIN with the model that uses the API>\n","\n","response = chain_api.invoke(prompt) # Invoke\n","print(\"RESPONSE using Mistral through API\")\n","print(\"-\"*len(\"RESPONSE using Mistral through API\"))\n","\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"images/doit.png\" alt=\"drawing\" width=\"24px\"/>  `TRYITYourself_2`\n","Prompt: summarize, translate, etc."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#  <TRYITYourself_2>: Prompt based on suggestions\n","prompt = '''\n","<ADD YOUR PROMPT HERE>\n","'''\n","response = chain.invoke(prompt)\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### Let's show the difference between large and small models...\n","\n","*We need to define a prompt that intrigues **creativity**, **reasonability** and **complexity***"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt = '''\n","You are a research assistant helping to summarize and expand \\\n","upon the following abstract from a scientific paper. \\\n","\n","First, summarize the key points of the abstract in a clear and concise \\\n","manner suitable for a general audience. Then, generate three original \\\n","and creative research questions that could be pursued in a follow-up study. \\\n","\n","Finally, write a brief paragraph discussing potential real-world applications of this research.\"\n","\n","Abstract:\n","\"In recent years, advancements in machine learning algorithms have led to significant breakthroughs in natural language processing (NLP). However, challenges remain in enabling models to understand nuanced human communication and context, particularly in specialized fields like legal and medical domains. This paper proposes a novel transformer-based architecture that integrates domain-specific knowledge graphs to enhance contextual understanding in these fields. Experimental results demonstrate improved accuracy and reduced bias in complex legal text interpretation and medical diagnosis generation.\"\n","\n","'''\n","\n","# 123 Billion\n","model_api_big = ChatMistralAI(model=\"mistral-large-latest\", temperature=0.0) # Load Mistral7b or Mixtral8x7B throught the API\n","chain_api_big = model_api_big | StrOutputParser()\n","response_big = chain_api_big.invoke(prompt) \n","\n","# 7B\n","response_small = chain_api.invoke(prompt) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(Markdown(response_small))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(Markdown(response_big))"]},{"cell_type":"markdown","metadata":{},"source":["### Changing the temperature settings"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt = \"\"\"\n","Imagine the characters from The IT Crowd, Harry Potter, \\\n","and The Lord of the Rings are brainstorming one unique \\\n","idea each to combat climate change using their skills. \\\n","Pick a chracter from each, Summarize their suggestions \\\n","in one sentence each and be brief.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Temperature 0 \n","model_api = ChatMistralAI(temperature=0.0) # Load Mistral7b from LM Studio local server \n","chain = model_api | StrOutputParser()\n","response = chain.invoke(prompt)\n","print(response)\n","print(\"-\"*100)\n","response = chain.invoke(prompt)\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"images/doit.png\" alt=\"drawing\" width=\"24px\"/>  `TRYITYourself_3`\n","Run and set the temperature to 0.9"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TRYITYourself_3 \n","model_api = None # <INIT Mistral 7b via API and set temperature>\n","chain = model_api | StrOutputParser()\n","response = chain.invoke(prompt)\n","print(response)\n","print(\"-\"*100)\n","response = chain.invoke(prompt)\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Zero-shot\n","\n","- Here is an example of zero-shot prompting.\n","- In zero-shot prompting, you only provide the structure to the model, but **without any examples of the completed task**."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt = \"\"\"\n","Text: \"The government announced a new policy aimed at improving healthcare access across rural areas.\"\n","Category: \n","\"\"\"\n","\n","chain = model_local | StrOutputParser()\n","\n","print(chain.invoke(prompt))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Let's add an explanation\n","prompt = \"\"\"\n","Classify the following text into one of these categories: Politics, Technology, Sports, Entertainment.\n","\n","\"\"\"+ prompt\n","\n","chain = model_local | StrOutputParser()\n","\n","print(chain.invoke(prompt))\n"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"images/doit.png\" alt=\"drawing\" width=\"24px\"/>  `TRYITYourself_4`\n","REPEAT For another task: For example sentiment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TRYITYourself_4\n","prompt = \"\"\"\n","<ADD PROMPT HERE>\n","\"\"\"\n","\n","chain = model_local | StrOutputParser()\n","\n","print(chain.invoke(prompt))\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 Few Shot\n","\n","- Here is an example of few-shot prompting.\n","- In few-shot prompting, you provide n examples and it is called n-shot."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt = \"\"\"\n","Classify the following news article into one of these categories: Politics, Technology, Sports, Entertainment.\n","\n","Text: \"Mixtral released their new Open-source model.\"\n","Category: Technology\n","\n","Text: \"The Lakers secured a thrilling victory in the NBA playoffs last night\"\n","Category: Sports\n","\n","Text: \"A new movie starring renowned actors is set to release this summer.\"\n","Category: Entertainment\n","\n","Text: \"The government announced a new policy aimed at improving healthcare access across rural areas.\"\n","Category:\n","\n","\"\"\"\n","\n","chain = model_local | StrOutputParser()\n","\n","print(chain.invoke(prompt))"]},{"cell_type":"markdown","metadata":{},"source":["### Specifying the Output Format\n","- You can also specify the format in which you want the model to respond.\n","\n","<img src=\"images/doit.png\" alt=\"drawing\" width=\"24px\"/>  `TRYITYourself_5`\n","ADD a sentence to command the LLM to return the category only"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TRYITYourself_5\n","prompt_output = prompt + \"\\n <ADD PROMPT to limit output formt>\"\n","\n","chain = model_local | StrOutputParser()\n","\n","print(chain.invoke(prompt_output))\n","\n","# Let us rerun by explicitly explaining each section"]},{"cell_type":"markdown","metadata":{},"source":["### We tried small models, let's try bigger model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(chain_api_big.invoke(prompt_output))"]},{"cell_type":"markdown","metadata":{},"source":["#### Let us try again with small model with the following enhancements\n","\n","- Add a section title clarifying the prompt structure (Exampples, Task)\n","- Explicitly state the format"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt = \"\"\"\n","Classify the following news article into one of these categories: Politics, Technology, Sports, Entertainment.\n","\n","# Examples\n","Text: \"Mixtral released their new Open-source model.\"\n","Category: Technology\n","\n","Text: \"The Lakers secured a thrilling victory in the NBA playoffs last night\"\n","Category: Sports\n","\n","Text: \"A new movie starring renowned actors is set to release this summer.\"\n","Category: Entertainment\n","\n","# Task\n","Text: \"The government announced a new policy aimed at improving healthcare access across rural areas.\"\n","Category:\n","\n","\"\"\"\n","\n","chain = model_local | StrOutputParser()\n","print(\"Added Section titles:\\n\", chain.invoke(prompt))\n","\n","prompt_output = prompt + \"\\n Give a one word response that can have one of the categories value. Do not provide any explanation, or any extra information.\"\n","print(\"and output format...\\n LLM Response: \", chain.invoke(prompt_output))\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.3 Role Playing Prompting under Zero-shot\n","In this section, we use how to use role playing prompting under zero-shot setting. \n","\n","For example, check paper [Better Zero-Shot Reasoning with Role-Play Prompting (Kong, 2024)](https://arxiv.org/pdf/2308.07702)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt = \"\"\"\n","Xavier was 4 feet tall and grew 3 inches. \\\n","Cole was 50 inches tall and grew 2 inches over the summer. \\\n","What is the difference between Cole and Xavier's height now?\n","\"\"\"\n","\n","response = chain.invoke(prompt)\n","print(response)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"images/doit.png\" alt=\"drawing\" width=\"24px\"/>  `TRYITYourself_6`\n","Prepend a role to your prompt: for example, \"From now on...\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TRYITYourself_6\n","role = \"From now on, you are <ADD ROLE>\"\n","prompt_role = f\"{role}\\n{prompt}\"\n","\n","response = chain.invoke(prompt_role)\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt = \"\"\"Write a review for the paper: Better Zero-Shot Reasoning with Role-Play Prompting from https://arxiv.org/pdf/2308.07702.\n","\"\"\"\n","print(chain.invoke(prompt))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["role = \"\"\"\n","From now on, you are senior researcher in NlP.\n","\"\"\"\n","\n","prompt_role= \"\"\"{role}\n","Write a review for the paper: Better Zero-Shot Reasoning with Role-Play Prompting from https://arxiv.org/pdf/2308.07702.\n","\"\"\"\n","print(chain.invoke(prompt_role))"]},{"cell_type":"markdown","metadata":{},"source":["### 3.4 Chain-of-Though Prompting under Zero-shot\n","In this section we cover CoT-Zero-Shot\n","\n","Original CoT paper [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (Wei, 2023)](https://arxiv.org/pdf/2201.11903)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt = \"\"\"\n","The cafeteria had 43 apples. \\\n","Someone ate 10, and 5 were thrown away. \\\n","If they bought 7 and then used 18 to make lunch, how many apples do they have? \n","\"\"\"\n","\n","# reinit chain\n","chain = CustomLLM() | StrOutputParser()\n","response = chain.invoke(prompt)\n","print(response) # Answer should be 17"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"images/doit.png\" alt=\"drawing\" width=\"24px\"/>  `TRYITYourself_7`\n","\n","Try to improve the prompt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TRYITYourself_7\n","cot = \"<INVOKE REASONING>\"\n","prompt_cot = f\"{prompt}\\n{cot}\"\n","\n","response = chain.invoke(prompt_cot)\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### LLM Reasoning\n","- A good resource for reasoning [Edge 353: A New Series About Reasoning in Foundation Models](https://thesequence.substack.com/p/edge-353-a-new-series-about-reasoning?utm_source=publication-search)\n","  \n","  > Reasoning is one of the core building blocks and marvels of human cognition. Conceptually, reasoning refers to the ability of models to work through a problem in a logical and systematic way to arrive to a conclusion. Obviously, reasoning assumes neither the steps nor the solutions are included as part of the training dataset.\n","\n","  > In the context of LLMs, reasoning is typically seen as a property that emerges after certain scale and is not applicable to small models. Some simpler forms of reasoning can be influenced via prompting and in-context learning while a new school have emerged around multi-step reasoning. In the latter area, we can find many variants of the chain-of-thought(CoT) method such as tree-of-thoughts or graph-of-thoughts."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"}},"nbformat":4,"nbformat_minor":2}
